{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-7bce5486ca52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Gensim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpora\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlemmatize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimple_preprocess\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# !{sys.executable} -m spacy download en\n",
    "import re, numpy as np, pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim, spacy, logging, warnings\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import lemmatize, simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use', 'not', 'would', 'say', 'could', '_', 'be', 'know', 'good', 'go', 'get', 'do', 'done', 'try', 'many', 'some', 'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right', 'line', 'even', 'also', 'may', 'take', 'come'])\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2361, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>From: irwin@cmptrc.lonestar.org (Irwin Arnstei...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10007</th>\n",
       "      <td>From: jet@netcom.Netcom.COM (J. Eric Townsend)...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10008</th>\n",
       "      <td>From: gld@cunixb.cc.columbia.edu (Gary L Dare)...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10017</th>\n",
       "      <td>From: nstramer@supergas.dazixco.ingr.com (Naft...</td>\n",
       "      <td>17</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10019</th>\n",
       "      <td>From: mussack@austin.ibm.com (Christopher Muss...</td>\n",
       "      <td>15</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  target  \\\n",
       "10     From: irwin@cmptrc.lonestar.org (Irwin Arnstei...       8   \n",
       "10007  From: jet@netcom.Netcom.COM (J. Eric Townsend)...       8   \n",
       "10008  From: gld@cunixb.cc.columbia.edu (Gary L Dare)...      10   \n",
       "10017  From: nstramer@supergas.dazixco.ingr.com (Naft...      17   \n",
       "10019  From: mussack@austin.ibm.com (Christopher Muss...      15   \n",
       "\n",
       "                 target_names  \n",
       "10            rec.motorcycles  \n",
       "10007         rec.motorcycles  \n",
       "10008        rec.sport.hockey  \n",
       "10017   talk.politics.mideast  \n",
       "10019  soc.religion.christian  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dataset\n",
    "df = pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')\n",
    "df = df.loc[df.target_names.isin(['soc.religion.christian', 'rec.sport.hockey', 'talk.politics.mideast', 'rec.motorcycles']) , :]\n",
    "print(df.shape)  #> (2361, 3)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sent in sentences:\n",
    "        sent = re.sub('\\S*@\\S*\\s?', '', sent)  # remove emails\n",
    "        sent = re.sub('\\s+', ' ', sent)  # remove newline chars\n",
    "        sent = re.sub(\"\\'\", \"\", sent)  # remove single quotes\n",
    "        sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
    "        yield(sent)  \n",
    "\n",
    "# Convert to list\n",
    "data = df.content.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "print(data_words[:1])\n",
    "# [['from', 'irwin', 'arnstein', 'subject', 're', 'recommendation', 'on', 'duc', 'summary', 'whats', 'it', 'worth', 'distribution', 'usa', 'expires', 'sat', 'may', 'gmt', ...trucated...]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# !python3 -m spacy download en  # run in terminal once\n",
    "def process_words(texts, stop_words=stop_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"Remove Stopwords, Form Bigrams, Trigrams and Lemmatization\"\"\"\n",
    "    texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "    texts = [bigram_mod[doc] for doc in texts]\n",
    "    texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "    texts_out = []\n",
    "    nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    # remove stopwords once more after lemmatization\n",
    "    texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts_out]    \n",
    "    return texts_out\n",
    "\n",
    "data_ready = process_words(data_words)  # processed Text Data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_ready)\n",
    "\n",
    "# Create Corpus: Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in data_ready]\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=4, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=10,\n",
    "                                           passes=10,\n",
    "                                           alpha='symmetric',\n",
    "                                           iterations=100,\n",
    "                                           per_word_topics=True)\n",
    "\n",
    "pprint(lda_model.print_topics())\n",
    "#> [(0,\n",
    "#>   '0.017*\"write\" + 0.015*\"people\" + 0.014*\"organization\" + 0.014*\"article\" + '\n",
    "#>   '0.013*\"time\" + 0.008*\"give\" + 0.008*\"first\" + 0.007*\"tell\" + 0.007*\"new\" + '\n",
    "#>   '0.007*\"question\"'),\n",
    "#>  (1,\n",
    "#>   '0.008*\"christian\" + 0.008*\"believe\" + 0.007*\"god\" + 0.007*\"law\" + '\n",
    "#>   '0.006*\"state\" + 0.006*\"israel\" + 0.006*\"israeli\" + 0.005*\"exist\" + '\n",
    "#>   '0.005*\"way\" + 0.004*\"bible\"'),\n",
    "#>  (2,\n",
    "#>   '0.024*\"armenian\" + 0.012*\"bike\" + 0.006*\"kill\" + 0.006*\"work\" + '\n",
    "#>   '0.005*\"well\" + 0.005*\"year\" + 0.005*\"sumgait\" + 0.005*\"soldier\" + '\n",
    "#>   '0.004*\"way\" + 0.004*\"ride\"'),\n",
    "#>  (3,\n",
    "#>   '0.019*\"team\" + 0.019*\"game\" + 0.013*\"hockey\" + 0.010*\"player\" + '\n",
    "#>   '0.009*\"play\" + 0.009*\"win\" + 0.009*\"nhl\" + 0.009*\"year\" + 0.009*\"hawk\" + '\n",
    "#>   '0.009*\"season\"')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel=None, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data_ready)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "df_dominant_topic.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display setting to show more characters in column\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=False).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Representative Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_lens = [len(d) for d in df_dominant_topic.Text]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(16,7), dpi=160)\n",
    "plt.hist(doc_lens, bins = 1000, color='navy')\n",
    "plt.text(750, 100, \"Mean   : \" + str(round(np.mean(doc_lens))))\n",
    "plt.text(750,  90, \"Median : \" + str(round(np.median(doc_lens))))\n",
    "plt.text(750,  80, \"Stdev   : \" + str(round(np.std(doc_lens))))\n",
    "plt.text(750,  70, \"1%ile    : \" + str(round(np.quantile(doc_lens, q=0.01))))\n",
    "plt.text(750,  60, \"99%ile  : \" + str(round(np.quantile(doc_lens, q=0.99))))\n",
    "\n",
    "plt.gca().set(xlim=(0, 1000), ylabel='Number of Documents', xlabel='Document Word Count')\n",
    "plt.tick_params(size=16)\n",
    "plt.xticks(np.linspace(0,1000,9))\n",
    "plt.title('Distribution of Document Word Counts', fontdict=dict(size=22))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-cfc41bd4707a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcolor\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmcolors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTABLEAU_COLORS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# more colors: 'mcolors.XKCD_COLORS'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m160\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msharex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msharey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n",
    "\n",
    "fig, axes = plt.subplots(2,2,figsize=(16,14), dpi=160, sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):    \n",
    "    df_dominant_topic_sub = df_dominant_topic.loc[df_dominant_topic.Dominant_Topic == i, :]\n",
    "    doc_lens = [len(d) for d in df_dominant_topic_sub.Text]\n",
    "    ax.hist(doc_lens, bins = 1000, color=cols[i])\n",
    "    ax.tick_params(axis='y', labelcolor=cols[i], color=cols[i])\n",
    "    sns.kdeplot(doc_lens, color=\"black\", shade=False, ax=ax.twinx())\n",
    "    ax.set(xlim=(0, 1000), xlabel='Document Word Count')\n",
    "    ax.set_ylabel('Number of Documents', color=cols[i])\n",
    "    ax.set_title('Topic: '+str(i), fontdict=dict(size=16, color=cols[i]))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.90)\n",
    "plt.xticks(np.linspace(0,1000,9))\n",
    "fig.suptitle('Distribution of Document Word Counts by Dominant Topic', fontsize=22)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-e235a46d8ede>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 1. Wordcloud of Top N words in each topic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmcolors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "# 1. Wordcloud of Top N words in each topic\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n",
    "\n",
    "cloud = WordCloud(stopwords=stop_words,\n",
    "                  background_color='white',\n",
    "                  width=2500,\n",
    "                  height=1800,\n",
    "                  max_words=10,\n",
    "                  colormap='tab10',\n",
    "                  color_func=lambda *args, **kwargs: cols[i],\n",
    "                  prefer_horizontal=1.0)\n",
    "\n",
    "topics = lda_model.show_topics(formatted=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10,10), sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    fig.add_subplot(ax)\n",
    "    topic_words = dict(topics[i][1])\n",
    "    cloud.generate_from_frequencies(topic_words, max_font_size=300)\n",
    "    plt.gca().imshow(cloud)\n",
    "    plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.axis('off')\n",
    "plt.margins(x=0, y=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lda_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-3105a4a9aef8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtopics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_topics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformatted\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdata_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw_list\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_ready\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mw_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcounter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_flat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lda_model' is not defined"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "topics = lda_model.show_topics(formatted=False)\n",
    "data_flat = [w for w_list in data_ready for w in w_list]\n",
    "counter = Counter(data_flat)\n",
    "\n",
    "out = []\n",
    "for i, topic in topics:\n",
    "    for word, weight in topic:\n",
    "        out.append([word, i , weight, counter[word]])\n",
    "\n",
    "df = pd.DataFrame(out, columns=['word', 'topic_id', 'importance', 'word_count'])        \n",
    "\n",
    "# Plot Word Count and Weights of Topic Keywords\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16,10), sharey=True, dpi=160)\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.bar(x='word', height=\"word_count\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.5, alpha=0.3, label='Word Count')\n",
    "    ax_twin = ax.twinx()\n",
    "    ax_twin.bar(x='word', height=\"importance\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.2, label='Weights')\n",
    "    ax.set_ylabel('Word Count', color=cols[i])\n",
    "    ax_twin.set_ylim(0, 0.030); ax.set_ylim(0, 3500)\n",
    "    ax.set_title('Topic: ' + str(i), color=cols[i], fontsize=16)\n",
    "    ax.tick_params(axis='y', left=False)\n",
    "    ax.set_xticklabels(df.loc[df.topic_id==i, 'word'], rotation=30, horizontalalignment= 'right')\n",
    "    ax.legend(loc='upper left'); ax_twin.legend(loc='upper right')\n",
    "\n",
    "fig.tight_layout(w_pad=2)    \n",
    "fig.suptitle('Word Count and Importance of Topic Keywords', fontsize=22, y=1.05)    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lda_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-a4e9e11f5a4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRectangle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0msentences_chart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m13\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mcorp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmycolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcolor\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmcolors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTABLEAU_COLORS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lda_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Sentence Coloring of N Sentences\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "def sentences_chart(lda_model=lda_model, corpus=corpus, start = 0, end = 13):\n",
    "    corp = corpus[start:end]\n",
    "    mycolors = [color for name, color in mcolors.TABLEAU_COLORS.items()]\n",
    "\n",
    "    fig, axes = plt.subplots(end-start, 1, figsize=(20, (end-start)*0.95), dpi=160)       \n",
    "    axes[0].axis('off')\n",
    "    for i, ax in enumerate(axes):\n",
    "        if i > 0:\n",
    "            corp_cur = corp[i-1] \n",
    "            topic_percs, wordid_topics, wordid_phivalues = lda_model[corp_cur]\n",
    "            word_dominanttopic = [(lda_model.id2word[wd], topic[0]) for wd, topic in wordid_topics]    \n",
    "            ax.text(0.01, 0.5, \"Doc \" + str(i-1) + \": \", verticalalignment='center',\n",
    "                    fontsize=16, color='black', transform=ax.transAxes, fontweight=700)\n",
    "\n",
    "            # Draw Rectange\n",
    "            topic_percs_sorted = sorted(topic_percs, key=lambda x: (x[1]), reverse=True)\n",
    "            ax.add_patch(Rectangle((0.0, 0.05), 0.99, 0.90, fill=None, alpha=1, \n",
    "                                   color=mycolors[topic_percs_sorted[0][0]], linewidth=2))\n",
    "\n",
    "            word_pos = 0.06\n",
    "            for j, (word, topics) in enumerate(word_dominanttopic):\n",
    "                if j < 14:\n",
    "                    ax.text(word_pos, 0.5, word,\n",
    "                            horizontalalignment='left',\n",
    "                            verticalalignment='center',\n",
    "                            fontsize=16, color=mycolors[topics],\n",
    "                            transform=ax.transAxes, fontweight=700)\n",
    "                    word_pos += .009 * len(word)  # to move the word for the next iter\n",
    "                    ax.axis('off')\n",
    "            ax.text(word_pos, 0.5, '. . .',\n",
    "                    horizontalalignment='left',\n",
    "                    verticalalignment='center',\n",
    "                    fontsize=16, color='black',\n",
    "                    transform=ax.transAxes)       \n",
    "\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.suptitle('Sentence Topic Coloring for Documents: ' + str(start) + ' to ' + str(end-2), fontsize=22, y=0.95, fontweight=700)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "sentences_chart()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lda_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-5ea2ada44643>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdominant_topics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopic_percentages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mdominant_topics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopic_percentages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtopics_per_document\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Distribution of Dominant Topics in Each Document\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lda_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Sentence Coloring of N Sentences\n",
    "def topics_per_document(model, corpus, start=0, end=1):\n",
    "    corpus_sel = corpus[start:end]\n",
    "    dominant_topics = []\n",
    "    topic_percentages = []\n",
    "    for i, corp in enumerate(corpus_sel):\n",
    "        topic_percs, wordid_topics, wordid_phivalues = model[corp]\n",
    "        dominant_topic = sorted(topic_percs, key = lambda x: x[1], reverse=True)[0][0]\n",
    "        dominant_topics.append((i, dominant_topic))\n",
    "        topic_percentages.append(topic_percs)\n",
    "    return(dominant_topics, topic_percentages)\n",
    "\n",
    "dominant_topics, topic_percentages = topics_per_document(model=lda_model, corpus=corpus, end=-1)            \n",
    "\n",
    "# Distribution of Dominant Topics in Each Document\n",
    "df = pd.DataFrame(dominant_topics, columns=['Document_Id', 'Dominant_Topic'])\n",
    "dominant_topic_in_each_doc = df.groupby('Dominant_Topic').size()\n",
    "df_dominant_topic_in_each_doc = dominant_topic_in_each_doc.to_frame(name='count').reset_index()\n",
    "\n",
    "# Total Topic Distribution by actual weight\n",
    "topic_weightage_by_doc = pd.DataFrame([dict(t) for t in topic_percentages])\n",
    "df_topic_weightage_by_doc = topic_weightage_by_doc.sum().to_frame(name='count').reset_index()\n",
    "\n",
    "# Top 3 Keywords for each Topic\n",
    "topic_top3words = [(i, topic) for i, topics in lda_model.show_topics(formatted=False) \n",
    "                                 for j, (topic, wt) in enumerate(topics) if j < 3]\n",
    "\n",
    "df_top3words_stacked = pd.DataFrame(topic_top3words, columns=['topic_id', 'words'])\n",
    "df_top3words = df_top3words_stacked.groupby('topic_id').agg(', \\n'.join)\n",
    "df_top3words.reset_index(level=0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_dominant_topic_in_each_doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-d86136f3454e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Topic Distribution by Dominant Topics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Dominant_Topic'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'count'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_dominant_topic_in_each_doc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'firebrick'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_dominant_topic_in_each_doc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDominant_Topic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mtick_formatter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFuncFormatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Topic '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;34m'\\n'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdf_top3words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_top3words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopic_id\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'words'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_dominant_topic_in_each_doc' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x480 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# Plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4), dpi=120, sharey=True)\n",
    "\n",
    "# Topic Distribution by Dominant Topics\n",
    "ax1.bar(x='Dominant_Topic', height='count', data=df_dominant_topic_in_each_doc, width=.5, color='firebrick')\n",
    "ax1.set_xticks(range(df_dominant_topic_in_each_doc.Dominant_Topic.unique().__len__()))\n",
    "tick_formatter = FuncFormatter(lambda x, pos: 'Topic ' + str(x)+ '\\n' + df_top3words.loc[df_top3words.topic_id==x, 'words'].values[0])\n",
    "ax1.xaxis.set_major_formatter(tick_formatter)\n",
    "ax1.set_title('Number of Documents by Dominant Topic', fontdict=dict(size=10))\n",
    "ax1.set_ylabel('Number of Documents')\n",
    "ax1.set_ylim(0, 1000)\n",
    "\n",
    "# Topic Distribution by Topic Weights\n",
    "ax2.bar(x='index', height='count', data=df_topic_weightage_by_doc, width=.5, color='steelblue')\n",
    "ax2.set_xticks(range(df_topic_weightage_by_doc.index.unique().__len__()))\n",
    "ax2.xaxis.set_major_formatter(tick_formatter)\n",
    "ax2.set_title('Number of Documents by Topic Weightage', fontdict=dict(size=10))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lda_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-2651b3e09edf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Get topic weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtopic_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow_list\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mtopic_weights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrow_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lda_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Get topic weights and dominant topics ------------\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import Label\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "# Get topic weights\n",
    "topic_weights = []\n",
    "for i, row_list in enumerate(lda_model[corpus]):\n",
    "    topic_weights.append([w for i, w in row_list[0]])\n",
    "\n",
    "# Array of topic weights    \n",
    "arr = pd.DataFrame(topic_weights).fillna(0).values\n",
    "\n",
    "# Keep the well separated points (optional)\n",
    "arr = arr[np.amax(arr, axis=1) > 0.35]\n",
    "\n",
    "# Dominant topic number in each doc\n",
    "topic_num = np.argmax(arr, axis=1)\n",
    "\n",
    "# tSNE Dimension Reduction\n",
    "tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n",
    "tsne_lda = tsne_model.fit_transform(arr)\n",
    "\n",
    "# Plot the Topic Clusters using Bokeh\n",
    "output_notebook()\n",
    "n_topics = 4\n",
    "mycolors = np.array([color for name, color in mcolors.TABLEAU_COLORS.items()])\n",
    "plot = figure(title=\"t-SNE Clustering of {} LDA Topics\".format(n_topics), \n",
    "              plot_width=900, plot_height=700)\n",
    "plot.scatter(x=tsne_lda[:,0], y=tsne_lda[:,1], color=mycolors[topic_num])\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyLDAvis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-2973fb578f4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgensim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mvis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid2word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mvis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyLDAvis'"
     ]
    }
   ],
   "source": [
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary=lda_model.id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
